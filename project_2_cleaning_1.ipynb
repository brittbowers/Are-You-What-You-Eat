{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Common Foods dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanCommonFoods(url):\n",
    "    '''\n",
    "    This function takes in the url of the common foods dataset and outputs\n",
    "    a clean dataframe with lower case food names\n",
    "    -----\n",
    "    Input: string\n",
    "    Output: DataFrame\n",
    "    '''\n",
    "    df_common_food = pd.read_csv(url)\n",
    "    df_common_food['FOOD NAME'] = [food.lower() for food in df_common_food['FOOD NAME']]\n",
    "    return df_common_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://query.data.world/s/ssqiubyapfnrrhrf2uhqqezfzhlr6q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common_food = cleanCommonFoods(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/df_common_food.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_common_food, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping foodsaroundtheworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking robots\n",
    "url = 'http://www.foodbycountry.com/robots.txt'\n",
    "response = requests.get(url)\n",
    "# Checking status code\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.foodbycountry.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCountryLinks(url):\n",
    "    '''\n",
    "    This function takes in the foodbycountry url and outputs a list of links\n",
    "    to specific country pages\n",
    "    -----\n",
    "    input: string\n",
    "    output: list\n",
    "    '''\n",
    "    response = requests.get(url)\n",
    "    soup_food = BeautifulSoup(response.text, 'lxml')\n",
    "    # Getting names of countries in a table based on class tag\n",
    "    country_links = [x.get('href') for x in soup_food.find_all(class_= 'list-group-item col-sm-4')]\n",
    "    return country_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_links = getCountryLinks(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listCountriesPages(country_links):\n",
    "    '''\n",
    "    This function takes in a list of links to country pages and returns the content\n",
    "    on the page in a list and the countries in a list\n",
    "    ----\n",
    "    input: list\n",
    "    output: list, list\n",
    "    '''\n",
    "    countries = []\n",
    "    food_pages = []\n",
    "    for link in country_links:\n",
    "        countries.append(link[link.find('/')+1:link.find('.')])\n",
    "        country_url = url + link\n",
    "        response = requests.get(country_url)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        a_page =[x.text.replace('\\n', ' ').lower() for x in soup.find_all('p')]\n",
    "        for each in a_page:\n",
    "            new = ''.join(map(str, a_page))\n",
    "        food_pages.append(new)\n",
    "    food_pages = [page.split(' ') for page in food_pages]\n",
    "    return countries, food_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries, food_pages = listCountriesPages(country_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DF of food, food group, and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countryFoodDF(df_common_food, food_pages):\n",
    "    '''\n",
    "    This function takes in a dataframe of common foods and a list of text scraped from \n",
    "    each country page. It returns a dataframe of all foods, food groups, and associated countries\n",
    "    -----\n",
    "    inputs: DataFrame, list\n",
    "    outputs: DataFrame\n",
    "    '''\n",
    "    list_foods = []\n",
    "    list_countries = []\n",
    "    list_groups = []\n",
    "    i = 0\n",
    "    for page in food_pages:\n",
    "        for food,group in zip(df_common_food['FOOD NAME'],df_common_food['GROUP']):\n",
    "            if food in page:\n",
    "                list_foods.append(food)\n",
    "                list_countries.append(countries[i])\n",
    "                list_groups.append(group)\n",
    "        i += 1\n",
    "    df_country_foods = pd.DataFrame({'food':list_foods, 'group':list_groups, 'country': list_countries})\n",
    "    return df_country_foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_foods = countryFoodDF(df_common_food, food_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/df_country_foods.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_country_foods, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Foods and Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/df_country_foods_1.pickle', 'rb') as read_file:\n",
    "    df_country_foods_1 = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairing down the food groups (5 main groups according to https://www.eatforhealth.gov.au/food-essentials/five-food-groups:\n",
    "\n",
    "    1) breads, cereals, rice, pasta, noodles and other grains\n",
    "\n",
    "    2) vegetables and legumes\n",
    "    \n",
    "    3) fruit\n",
    "\n",
    "    4) milk, yoghurt, cheese and/or alternatives\n",
    "\n",
    "    5) lean meat, fish, poultry, eggs, nuts and legumes.\n",
    "\n",
    "    6) Other: Baking products, Sugar, confectionaries, beverages, coffee, tea, etc.\n",
    "\n",
    "I'm going to remove herbs and spices on the grounds that it doesn't make up a large enough volume of the food.\n",
    "\n",
    "Removing dishes, because foods are not specified.\n",
    "\n",
    "Removing fats and oils, because these are encapsulated by other food groups\n",
    "\n",
    "\n",
    "Pulse = legume = 5\n",
    "Gourds = fruits = 3\n",
    "\n",
    "\n",
    "Legumes are in both the vegetables category and meats (this is because nutritionally they can substitute for \n",
    "vegetables. I'm going to leave them as a seperate feature for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Teas', 'Pulses', 'Coffee and coffee products', 'Gourds',\n",
       "       'Herbs and Spices', 'Vegetables', 'Fruits',\n",
       "       'Cereals and cereal products', 'Milk and milk products',\n",
       "       'Baking goods', 'Beverages', 'Dishes', 'Aquatic foods', 'Eggs',\n",
       "       'Confectioneries', 'Cocoa and cocoa products', 'Animal foods',\n",
       "       'Nuts', 'Snack foods', 'Soy', 'Fats and oils'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country_foods.group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_groups = {'Teas': 'extra','Pulses': 'legumes', 'Coffee and coffee products': 'extra', \n",
    "                 'Gourds': 'fruits', 'Vegetables': 'vegetables', 'Fruits':'fruits', \n",
    "                 'Cereals and cereal products':'grains', 'Milk and milk products':'dairy', 'Baking goods':'extra',\n",
    "                 'Beverages':'extra', 'Beverages':'extra', 'Aquatic foods':'meats', 'Eggs':'meats', \n",
    "                 'Confectioneries':'extra', 'Cocoa and cocoa products':'extra', 'Animal foods':'meats',\n",
    "                 'Nuts':'meats', 'Snack foods':'extra', 'Soy':'meats'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_foods = df_country_foods[df_country_foods.group != 'Herbs and Spices']\n",
    "df_country_foods = df_country_foods[df_country_foods.group != 'Dishes']\n",
    "df_country_foods = df_country_foods[df_country_foods.group != 'Fats and oils']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_foods = df_country_foods.replace({'group':replace_groups})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_foods = df_country_foods.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting legumes in the meat group and renaming this group \"protein\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_foods = df_country_groups.replace({'legumes':'protein', 'meats':'protein'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dairy', 'extra', 'fruits', 'grains', 'protein', 'vegetables'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country_foods.group.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A few notes thus far**: \n",
    "\n",
    "    1) I'm removing the granulated regions below to be able to better group the data. The process of this\n",
    "        has caused me to think a bit more about food culture. Grouping all of the US together is a huge\n",
    "        assumption. Not sure this will turn up many signals. I have a new thought\n",
    "        New Thought - Grouping by cultural origin. I actual think that some of these countries which are still\n",
    "        fairly siloed may turn out a better signal\n",
    "    \n",
    "    2) I'm also not sure if these groups are grouping the right nutritional patterns. Might be worth it to find a \n",
    "        a dataset of nutritional content in these foods then group by that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_foods['country'] = [country.replace('-', ' ') for country in df_country_foods['country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,country in enumerate(df_country_foods['country']):\n",
    "    if re.search(r'^United States', country):\n",
    "        df_country_foods.loc[i, 'country'] = 'United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,country in enumerate(df_country_foods['country']):\n",
    "    if re.search(r'^Brazil', country):\n",
    "        df_country_foods.loc[i, 'country'] = 'Brazil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,country in enumerate(df_country_foods['country']):\n",
    "    if re.search(r'^Australia', country):\n",
    "        df_country_foods.loc[i, 'country'] = 'Australia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,country in enumerate(df_country_foods['country']):\n",
    "    if re.search(r'^Canada', country):\n",
    "        df_country_foods.loc[i, 'country'] = 'Canada'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by count of foods in each food group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_groups = df_country_foods.groupby(['country','group'], as_index = False)['food'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming to get normalized count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_groups['food'] = df_country_groups.groupby('country', as_index = False)['food'].transform(lambda x: x/x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/df_country_groups.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_country_groups, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Mean Height Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/df_country_groups.pickle', 'rb') as read_file:\n",
    "    df_country_groups = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_height = pd.read_csv('data/height_country.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1996"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_height['Year of birth'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering only most recent mean height\n",
    "df_height_recent = df_height[df_height['Year of birth'] == 1996]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_height_recent = df_height_recent.rename(columns = {'Year of birth':'year', 'Mean height (cm)':'mean', \n",
    "                         'Mean height lower 95% uncertainty interval (cm)':'lower95',\n",
    "                        'Mean height upper 95% uncertainty interval (cm)' : 'upper95',\n",
    "                                                     'Country':'country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_groups = df_country_groups.set_index('country').join(df_height_recent.set_index('country'), how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting legumes in the meats group, because it is essencially a \"protein group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_men_group = combined_groups[combined_groups['Sex'] == 'Men']\n",
    "combined_women_group = combined_groups[combined_groups['Sex'] == 'Women']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ISO', 'Sex', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_men_group = combined_men_group.drop(cols, axis = 1)\n",
    "combined_women_group = combined_women_group.drop(cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_men = combined_men_group[['food', 'group']]\n",
    "food_women = combined_women_group[['food', 'group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_men = food_men.pivot(columns = 'group', values = 'food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_women = food_women.pivot(columns = 'group', values = 'food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: there are still a lot of food groups with zero...this is a reason to fill out dataset\n",
    "food_men = food_men.replace(np.nan,0)\n",
    "food_women = food_women.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_men = combined_men_group.groupby('country')['mean'].mean()\n",
    "y_women = combined_women_group.groupby('country')['mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_men_group = food_men.join(y_men, how = 'left')\n",
    "combined_women_group = food_women.join(y_women, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/combined_women_group.pickle', 'wb') as to_write:\n",
    "    pickle.dump(combined_women_group, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/combined_men_group.pickle', 'wb') as to_write:\n",
    "    pickle.dump(combined_men_group, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tried to use Selenium for something that BeautifulSoup can do better\n",
    "#driver = webdriver.Chrome()\n",
    "#driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "##country_algeria=driver.find_element_by_class_name('list-group-item col-sm-4') # Find a country name\n",
    "##country_algeria.send_keys() # Click it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
